<!DOCTYPE html>
<html lang="en">
  <head>
    <link href='http://fonts.googleapis.com/css?family=Noticia+Text:400,700' rel='stylesheet' type='text/css' />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="description" content="">
    <meta name="author" content="keyan">

    <title> "The man of simple faith who loves learning for his burden is love" | keyan pishdadian </title>

    <link rel="stylesheet" href="/theme/css/style.css" type="text/css" />
    <link rel="stylesheet" href="/theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="/theme/css/font-awesome.css" type="text/css"/>
    <link rel="shortcut icon" href="/theme/images/favicon.ico">
  </head>
  <body>
    <div class=container>
<div class="header">
    <a href="index.html">keyan pishdadian</a> <span class="muted"></span>
</div>

<div class=navigation>
    <ul>
            <li><a href="/index.html">blog</a> </li>
            <li><a href="/archives.html">archive</a> </li>
            <li><a href="/pages/about-me.html">about</a> </li>
    </ul>
</div>
<div class=separator></div>        
        <div class=body>
    <h1 class="title"> "The man of simple faith who loves learning for his burden is love"</h1>
    <p class=date> 01 23 2015 </p>
    <p>That title was generated by my Markov chain text generator that I just finished working on. Even though it's stochastically generated text, I feel like it is speaking to me. That might sound strange, that's because it is.</p>
<p>This was a side project I did after a fellow Recurser and friend, <a href="https://github.com/amandapickering">Amanda</a>, talked about a <a href="https://twitter.com/milton_bot">twitter bot</a> she wrote that used Markov chains to make tweets. I have always been interested in working on an NLP project and decided this would be perfect to do in-between other things this week.</p>
<p>For the uninitiated, Markov chains are mathematical systems that transition from one state to another. Each transition depends only on the current state and not on the transitions that bring the system to the present state. We can design Markov chain models of a system to describe the likelihood of any particular transition occurring. For instance, constructing a Markov chain model for a sentence would allow us to know the probability that a certain word would follow any other word in that sentence. For example in the sentence:</p>
<blockquote>
<p>The lazy boy poked the lazy dog</p>
</blockquote>
<p>We know that if our current state is <strong>"lazy"</strong> then the probabilities of the two possible future states are 50% <strong>"boy"</strong> and 50% <strong>"dog"</strong>. In this project I used this idea to process a large input text (my favorite is <a href="https://www.gutenberg.org/ebooks/24055">The Sayings of Confucius</a>) and use the weighted probabilities of individual state changes to stochastically generate text which (hopefully) looks and sounds similar to the input.</p>
<p>I did this by creating a dictionary which kept a count of the instances that certain individual words followed each two word phrase in the input. I used one large dictionary where each key was a two word phrase, and each value was a <a href="https://docs.python.org/2/library/collections.html#collections.defaultdict">defaultdict</a>. The code for this is below:</p>
<div class="highlight"><pre><span class="k">if</span> <span class="n">current_token</span> <span class="ow">in</span> <span class="n">markov_dictionary</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_dictionary</span><span class="p">(</span><span class="n">markov_dictionary</span><span class="p">,</span>
                        <span class="n">tokens_list</span><span class="p">,</span>
                        <span class="n">current_token</span><span class="p">,</span>
                        <span class="n">next_index</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">markov_dictionary</span><span class="p">[</span><span class="n">current_token</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_dictionary</span><span class="p">(</span><span class="n">markov_dictionary</span><span class="p">,</span>
                        <span class="n">tokens_list</span><span class="p">,</span>
                        <span class="n">current_token</span><span class="p">,</span>
                        <span class="n">next_index</span><span class="p">)</span>
</pre></div>


<p>After this I just used the word counts to calculate a probability (0.0 - 1.0) that a word would follow the current state and used this to make a weighted randomized choice:</p>
<div class="highlight"><pre><span class="k">if</span> <span class="n">current_token</span> <span class="ow">in</span> <span class="n">markov_dictionary</span><span class="p">:</span>
<span class="n">denominator</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">current_word</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="n">denominator</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">current_word</span><span class="p">]</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">current_word</span><span class="p">]</span>
<span class="n">word</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">words</span><span class="p">,</span>
                                <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                <span class="n">p</span><span class="o">=</span><span class="n">weights</span><span class="p">))</span>
</pre></div>


<p>The result of all this is text that is oftentimes gibberish, but sometimes strangely poetic:</p>
<blockquote>
<p>In awe he is stable a man with enquiries to another state</p>
<p>Come from afar do we not rejoice to live unknown</p>
<p>They are unprincipled stern men of arts and learning delights</p>
<p>His face changed when he was asked what is meant by kindness without waste</p>
<p>The master said when a man of endless craving who never tires of his laughter he only takes when he has lost the way</p>
</blockquote>
<p>The rest of the code is available <a href="https://github.com/keyanp/MarkovGen">here</a>. I'm hoping to work more on my BitTorrent client this week, as I spent most of this past week fixing bugs in <a href="http://www.bpython-interpreter.org/"><em>bpython</em></a>. I'll probably talk more about that some other time.</p>

        </div>
        
<div class=footer>
  <p>
    <div class=social style="font-size: 27px;">
      <ul>
<script language="JavaScript">
          u = 'kpishdadian';
          s = 'gmail.com';
          document.write('<a href=\"mailto:' + u + '@' + s + '\" target=\"_blank\">');
        </script>
            <li><i class="icon-envelope icon-large"></i> </li>
        </a><a href="http://twitter.com/keyan__P" target="_blank"> <li> <i class="icon-twitter-sign icon-large"> </li></i> </a><a href="https://www.linkedin.com/profile/view?id=233825174" target="_blank"><li><i class="icon-linkedin-sign icon-large" ></i></li></a><a href="http://github.com/keyan" target="_blank"> <li> <i class="icon-github-sign icon-large"></i> </li> </a>
      </ul>
    </div>
  </p>
</div>    </div>
  </body>
</html>
